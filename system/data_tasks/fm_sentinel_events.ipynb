{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something\n",
      "['/Library/Frameworks/Python.framework/Versions/3.11/lib/python311.zip', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload', '', '/Users/davidsongikandi/Documents/Gikandi/Work/repo/duft-workspace-django/.venv/lib/python3.11/site-packages', '/Users/davidsongikandi/Documents/Gikandi/Work/repo/duft-workspace-django/duft', '/Users/davidsongikandi/Documents/Gikandi/Work/repo/duft-workspace-django/duft-server']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from data_task_helpers import something\n",
    "\n",
    "something()\n",
    "\n",
    "from api_data_task_executioner.data_task_tools import assert_dte_tools_available, get_resolved_parameters_for_connection, initialise_data_task, find_json_arg  # noqa: E402\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUFT Config: duft-config\n",
      "DUFT Config: duft-config\n",
      "[2024-08-27T17:08:12.023364] Jupyter Sample Data Task - INFO: Jupyter Sample Data Task initialised running in active mode\n",
      ">>> Jupyter Sample Data Task UPDATE: Jupyter Sample Data Task initialised running in active mode\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "environment = initialise_data_task(\"Jupyter Sample Data Task\", params=params)\n",
    "params[\"name\"] = params.get(\"customname\", params.get(\"name\", \"No parameters given!\"))\n",
    "params[\"sleep_time\"] = params.get(\"sleep_time\", 0.2)\n",
    "\n",
    "if not params:\n",
    "    environment.log_error(\"No parameters given!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaydebeapi\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sqlalchemy import create_engine\n",
    "from jaydebeapi import Connection\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Source and Destinaton Database Connections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUFT Config: duft-config\n",
      "DUFT Config: duft-config\n"
     ]
    }
   ],
   "source": [
    "source_environment = get_resolved_parameters_for_connection(\"EPMS_Source\")\n",
    "destination_environment = get_resolved_parameters_for_connection(\"EPMS_Destination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Filemaker Driver Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_jar_path = \"/Library/Java/Extensions/fmjdbc.jar\"\n",
    "driver_class = \"com.filemaker.jdbc.Driver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process File Maker Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_maker_connection():\n",
    "    try:\n",
    "        server = source_environment.get(\"server\")\n",
    "        username = source_environment.get(\"username\")\n",
    "        password = source_environment.get(\"password\")\n",
    "        return jaydebeapi.connect(driver_class, server, [username, password], driver_jar_path)\n",
    "    except Exception as ex:\n",
    "        return None\n",
    "\n",
    "\n",
    "def close_file_maker_connection(con: Connection):\n",
    "    if con is not None:\n",
    "        con.close()\n",
    "\n",
    "\n",
    "def fetch_file_maker_data(query: str, con: Connection):\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(query)\n",
    "    data_rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return data_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open connection to FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_connection = open_file_maker_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dim_patient Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_confs = {\n",
    "    \"query\": \"SELECT  r.name, d.name, f.name, f.code, p.id, p.sex, p.dob, p.maritalStatus, p.patientStatus, p.clientCode, pharmacyNumber, pmtctNumber, nameFirst, nameLast, phoneCellNumber, p.ageYear, resCurrentAddTown, resCurrentAddConstituency, resCurrentAddStreet, resPermanentAddTown, resPermanentAddConstituency, resPermanentAddStreet, idFacilityCurrent,  homeBasedCareOrg, homeBasedCareCode,  deathDate  FROM pat p inner join fac f on p.idFacilityCurrent = f.id  inner join region r on f.idregion=r.id inner join district d on f.idDistrict = d.id\",\n",
    "    \"cols\": ['region','district','current_facility', 'facility_code','client_id', 'sex', 'date_of_birth', 'marital_status','patient_status','client_code', 'pharmacy_code','pmtct_number', 'first_name','last_name','contact_number','age','current_town','current_constituency','current_street', 'permanent_town','permanent_constituency','permanent_street','id_facility_current', 'cbart_cargs_name', 'cbart_cargs_code', 'death_date']\n",
    "}\n",
    "\n",
    "patient_query = patient_confs.get(\"query\")\n",
    "patient_cols = patient_confs.get(\"cols\")\n",
    "\n",
    "patient_data = fetch_file_maker_data(patient_query, fm_connection)\n",
    "dim_pat_df = pd.DataFrame(patient_data, columns=patient_cols)\n",
    "\n",
    "dim_pat_df['date_of_birth'] = pd.to_datetime(dim_pat_df['date_of_birth'], errors='coerce')\n",
    "dim_pat_df['first_name'] = 'FName'\n",
    "dim_pat_df['last_name'] = 'LName'\n",
    "dim_pat_df['contact_number'] = '123456'\n",
    "\n",
    "dim_pat_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get patient latest transfer status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_tsfr_confs = {\n",
    "    \"query\": \"SELECT idpatient,  status, \\\"date\\\" FROM tsfr\",\n",
    "    \"cols\": ['client_id' ,'transfer_status', 'transfer_date']\n",
    "}\n",
    "\n",
    "fact_tsfr_query = fact_tsfr_confs.get(\"query\")\n",
    "fact_tsfr_cols = fact_tsfr_confs.get(\"cols\")\n",
    "\n",
    "fact_tsfr_data = fetch_file_maker_data(fact_tsfr_query, fm_connection)\n",
    "fact_tsfr_df = pd.DataFrame(fact_tsfr_data, columns=fact_tsfr_cols)\n",
    "\n",
    "fact_tsfr_df = fact_tsfr_df.dropna(subset=['transfer_date'])\n",
    "\n",
    "fact_tsfr_df = fact_tsfr_df.loc[fact_tsfr_df.groupby('client_id')['transfer_date'].idxmin()].reset_index(drop=True)\n",
    "fact_tsfr_df.head()\n",
    "\n",
    "fact_tsfr_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add transfer status to patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_pat_df = pd.merge(dim_pat_df, fact_tsfr_df, on='client_id', how='left')\n",
    "\n",
    "dim_pat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get first Weight and WHO Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_meas_confs = {\n",
    "    \"query\": \"SELECT idpatient, weight, whoStage,\\\"Date\\\" FROM Meas m\",\n",
    "    \"cols\": ['client_id', 'weight','who_stage', 'creation_date']\n",
    "}\n",
    "\n",
    "fact_meas_query = fact_meas_confs.get(\"query\")\n",
    "fact_meas_cols = fact_meas_confs.get(\"cols\")\n",
    "\n",
    "fact_meas_data = fetch_file_maker_data(fact_meas_query, fm_connection)\n",
    "fact_meas_df = pd.DataFrame(fact_meas_data, columns=fact_meas_cols)\n",
    "\n",
    "fact_meas_df = fact_meas_df.dropna(subset=['creation_date'])\n",
    "\n",
    "fact_meas_df = fact_meas_df.loc[fact_meas_df.groupby('client_id')['creation_date'].idxmin()].reset_index(drop=True)\n",
    "fact_meas_df.head()\n",
    "\n",
    "fact_meas_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_hiv_diagnosis Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_hiv_diagnosis_confs = {\n",
    "    \"query\": \"SELECT idpatient, hivconfirmationdate, hivconfirmatoryresultsdate, hivconfirmatoryresultstype, idfacilitycreate, fullDisclosureDAte FROM Cd\",\n",
    "    \"cols\": ['client_id', 'hiv_confirmation_date','hiv_confirmatory_result_date', 'hiv_confirmatory_result_type', 'hiv_diagnosis_facility_id','full_disclosure_date']\n",
    "}\n",
    "\n",
    "fact_hiv_diagnosis_query = fact_hiv_diagnosis_confs.get(\"query\")\n",
    "fact_hiv_diagnosis_cols = fact_hiv_diagnosis_confs.get(\"cols\")\n",
    "\n",
    "fact_hiv_diagnosis_data = fetch_file_maker_data(fact_hiv_diagnosis_query, fm_connection)\n",
    "fact_hiv_diagnosis_df = pd.DataFrame(fact_hiv_diagnosis_data, columns=fact_hiv_diagnosis_cols)\n",
    "\n",
    "fact_hiv_diagnosis_df['hiv_confirmation_date'] = pd.to_datetime(fact_hiv_diagnosis_df['hiv_confirmation_date'], errors='coerce')\n",
    "fact_hiv_diagnosis_df['hiv_confirmatory_result_date'] = pd.to_datetime(fact_hiv_diagnosis_df['hiv_confirmatory_result_date'], errors='coerce')\n",
    "\n",
    "fact_hiv_diagnosis_df = fact_hiv_diagnosis_df.dropna(subset=['hiv_confirmation_date'])\n",
    "\n",
    "fact_hiv_diagnosis_df = fact_hiv_diagnosis_df.loc[fact_hiv_diagnosis_df.groupby('client_id')['hiv_confirmation_date'].idxmin()].reset_index(drop=True)\n",
    "\n",
    "fact_hiv_diagnosis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Initial weight and WHO Stage to fact_hiv_diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_hiv_diagnosis_df = pd.merge(fact_hiv_diagnosis_df, fact_meas_df[['client_id','weight', 'who_stage']], on='client_id', how='left')\n",
    "\n",
    "fact_hiv_diagnosis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add dim_patient, fact_hiv_diagnosis to fact_sentinel_event dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df = pd.merge(dim_pat_df, fact_hiv_diagnosis_df, on='client_id', how='left')\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create hiv_enrolment dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fact_hiv_enrolment_confs = {\n",
    "    \"query\": \"SELECT c.idpatient, c.idfacilitycreate, c.hivenrolleddate, c.disclosureenrollmentdate, c.arteligiblereason, c.artstartdate, p.artnumber, p.artnumber, p.artnumberlegacy, c.idfacilityARTStart, tbScreenResult FROM pat p LEFT JOIN Cd c ON p.id=c.idpatient LEFT JOIN ia a  ON p.id=a.idpatient\",\n",
    "    \"cols\": ['client_id', 'hiv_enrollment_facility_id', 'hiv_enrollment_date', 'hiv_disclosure_enrollment_date','art_eligible_reason','art_start_date', 'quantum_number' , 'art_number', 'art_number_legacy', 'arv_initiating_facility','tb_screen_result']\n",
    "}\n",
    "\n",
    "\n",
    "fact_hiv_enrolment_query = fact_hiv_enrolment_confs.get(\"query\")\n",
    "fact_hiv_enrolment_cols = fact_hiv_enrolment_confs.get(\"cols\")\n",
    "\n",
    "fact_hiv_enrolment_data = fetch_file_maker_data(fact_hiv_enrolment_query, fm_connection)\n",
    "fact_hiv_enrolment_df = pd.DataFrame(fact_hiv_enrolment_data, columns=fact_hiv_enrolment_cols)\n",
    "\n",
    "fact_hiv_enrolment_df['hiv_enrollment_date'] = pd.to_datetime(fact_hiv_enrolment_df['hiv_enrollment_date'], errors='coerce')\n",
    "fact_hiv_enrolment_df['hiv_disclosure_enrollment_date'] = pd.to_datetime(fact_hiv_enrolment_df['hiv_disclosure_enrollment_date'], errors='coerce')\n",
    "fact_hiv_enrolment_df['art_start_date'] = pd.to_datetime(fact_hiv_enrolment_df['art_start_date'], errors='coerce')\n",
    "\n",
    "fact_hiv_enrolment_df = fact_hiv_enrolment_df.dropna(subset=['hiv_enrollment_date'])\n",
    "\n",
    "fact_hiv_enrolment_df = fact_hiv_enrolment_df.loc[fact_hiv_enrolment_df.groupby('client_id')['hiv_enrollment_date'].idxmin()].reset_index(drop=True)\n",
    "\n",
    "fact_hiv_enrolment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add fact_hiv_enrolment to fact_sentinel_event dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_hiv_enrolment_df, on='client_id', how='left')\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get first and last visit ids per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_visits_confs = {\n",
    "    \"query\": \"SELECT id, idpatient, visitDate FROM Fup\",\n",
    "    \"cols\": ['id', 'client_id', 'visit_date' ]\n",
    "}\n",
    "\n",
    "fact_visits_query = fact_visits_confs.get(\"query\")\n",
    "fact_visits_cols = fact_visits_confs.get(\"cols\")\n",
    "\n",
    "fact_visits_data = fetch_file_maker_data(fact_visits_query, fm_connection)\n",
    "fact_visits_df = pd.DataFrame(fact_visits_data, columns=fact_visits_cols)\n",
    "\n",
    "latest_visits_df = fact_visits_df.loc[fact_visits_df.groupby('client_id')['visit_date'].idxmax()]\n",
    "\n",
    "first_visits_df = fact_visits_df.loc[fact_visits_df.groupby('client_id')['visit_date'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create first_fact_visits dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_visits_confs = {\n",
    "    \"query\": \"SELECT DISTINCT f.idpatient, f.idfacilitycreate, f.visitDate FROM Fup f\",\n",
    "    \"cols\": ['client_id', 'visit_facility_id', 'visit_date']\n",
    "}\n",
    "\n",
    "fact_visits_query = fact_visits_confs.get(\"query\")\n",
    "fact_visits_cols = fact_visits_confs.get(\"cols\")\n",
    "\n",
    "ids = first_visits_df['id'].tolist()\n",
    "\n",
    "ids_str = ','.join(f\"'{id_}'\" for id_ in ids)\n",
    "\n",
    "fact_visits_query_updated = f\"{fact_visits_query} WHERE f.id IN ({ids_str})\"\n",
    "\n",
    "fact_visits_data = fetch_file_maker_data(fact_visits_query_updated, fm_connection)\n",
    "fact_first_visit_df = pd.DataFrame(fact_visits_data, columns=fact_visits_cols)\n",
    "\n",
    "fact_first_visit_df['visit_date'] = pd.to_datetime(fact_first_visit_df['visit_date'], errors='coerce')\n",
    "\n",
    "fact_first_visit_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add first visit info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = {\n",
    "    'visit_date': 'first_visit_date', \n",
    "    'visit_facility_id': 'first_visit_facility_id'\n",
    "}\n",
    "\n",
    "fact_first_visit_df = fact_first_visit_df[list(columns_to_add.keys()) + ['client_id']].rename(columns=columns_to_add)\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_first_visit_df, on='client_id', how='left')\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_last_visit dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_visits_confs = {\n",
    "    \"query\": \"SELECT DISTINCT f.idpatient, f.idfacilitycreate, f.visitDate, f.followupDate, f.scheduledDate, f.careModel, f.pregnantstatus, f.Breastfeeding, f.pregnantlmp, f.pregnantedd, f.ctxadherence, f.arvadherence, f.caremodel, r.code, r.line, cc.treatment, cc.dateTreatment, labResult, pf.stiGenitalUlcers, pf.stiVaginalUrethralDischarge, pf.stiScreenResult, f.oiDetail, f.oiOther FROM Fup f LEFT JOIN patFup pf on f.id=pf.id LEFT JOIN cc ON f.id=cc.idFollowUp LEFT JOIN rgm r ON f.id=r.idFollowUp\",\n",
    "    \"cols\": ['client_id', 'visit_facility_id', 'visit_date', 'next_visit_date', 'scheduled_visit_date', 'care_model', 'pregnancy_status', 'breast_feeding', 'lmp', 'edd', 'ctx_adherence', 'arv_adherence','care_model','current_regimen_code','current_regimen_line', 'cc_treatment_type','cc_treatment_date','cc_results', 'genital_ulcers','vaginal_urethral_discharge','sti_screening_result', 'oi', 'oi_other' ]\n",
    "}\n",
    "\n",
    "fact_visits_query = fact_visits_confs.get(\"query\")\n",
    "fact_visits_cols = fact_visits_confs.get(\"cols\")\n",
    "\n",
    "ids = latest_visits_df['id'].tolist()\n",
    "\n",
    "ids_str = ','.join(f\"'{id_}'\" for id_ in ids)\n",
    "\n",
    "fact_visits_query_updated = f\"{fact_visits_query} WHERE f.id IN ({ids_str})\"\n",
    "\n",
    "fact_visits_data = fetch_file_maker_data(fact_visits_query_updated, fm_connection)\n",
    "fact_last_visit_df = pd.DataFrame(fact_visits_data, columns=fact_visits_cols)\n",
    "\n",
    "fact_last_visit_df['visit_date'] = pd.to_datetime(fact_last_visit_df['visit_date'], errors='coerce')\n",
    "fact_last_visit_df['next_visit_date'] = pd.to_datetime(fact_last_visit_df['next_visit_date'], errors='coerce')\n",
    "\n",
    "fact_last_visit_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add last visit info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = {\n",
    "    'visit_date': 'last_visit_date',\n",
    "    'next_visit_date': 'last_next_visit_date', \n",
    "    'scheduled_visit_date': 'last_scheduled_visit_date', \n",
    "    'pregnancy_status': 'last_pregnancy_status', \n",
    "    'breast_feeding': 'last_breast_feeding', \n",
    "    'lmp': 'last_lmp', \n",
    "    'edd': 'last_edd',\n",
    "    'visit_facility_id': 'last_visit_facility_id',\n",
    "    'cc_treatment_type':'last_cc_treatment_type',\n",
    "    'cc_treatment_date': 'last_cc_treatment_date',\n",
    "    'cc_results': 'last_cc_results',\n",
    "    'oi':'last_oi', \n",
    "    'oi_other': 'last_oi_other',\n",
    "    'current_regimen_line': 'last_regimen_line'\n",
    "}\n",
    "\n",
    "fact_last_visit_df = fact_last_visit_df[list(columns_to_add.keys()) + ['client_id']].rename(columns=columns_to_add)\n",
    "\n",
    "max_last_visit_date = fact_last_visit_df['last_visit_date'].max()\n",
    "print(f'last_refresh_date: {max_last_visit_date}')\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_last_visit_df, on='client_id', how='left')\n",
    "\n",
    "fact_sentinel_event_df['last_visit_duration'] = (fact_sentinel_event_df['last_next_visit_date'].dt.year - fact_sentinel_event_df['last_visit_date'].dt.year) * 12 + (fact_sentinel_event_df['last_next_visit_date'].dt.month - fact_sentinel_event_df['last_visit_date'].dt.month)\n",
    "\n",
    "fact_sentinel_event_df['iit_date'] = fact_sentinel_event_df['last_next_visit_date'] + pd.Timedelta(days=29)\n",
    "\n",
    "fact_sentinel_event_df['iit_duration'] = (pd.Timestamp('today').normalize() - fact_sentinel_event_df['iit_date']).dt.days\n",
    "\n",
    "fact_sentinel_event_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_tbt dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_tbt_confs = {\n",
    "    \"query\": \"SELECT idpatient, idfacilitycreate, category, startDate, duration, stopDateExpected, stopDateActual , registrationNumber , site, siteDetail , outcome FROM tbt\",\n",
    "    \"cols\": ['client_id', 'tbt_facility_id', 'tbt_category', 'tbt_start_date', 'tbt_duration' ,'tbt_expected_stop_date', 'tbt_actual_stop_date', 'tbt_registration_number', 'tbt_site', 'tbt_site_detail', 'tbt_outcome']\n",
    "}\n",
    "\n",
    "fact_tbt_query = fact_tbt_confs.get(\"query\")\n",
    "fact_tbt_cols = fact_tbt_confs.get(\"cols\")\n",
    "\n",
    "fact_tbt_data = fetch_file_maker_data(fact_tbt_query, fm_connection)\n",
    "fact_tbt_df = pd.DataFrame(fact_tbt_data, columns=fact_tbt_cols)\n",
    "\n",
    "fact_tbt_df = fact_tbt_df.dropna(subset=['tbt_start_date'])\n",
    "\n",
    "fact_tbt_df = fact_tbt_df.loc[fact_tbt_df.groupby('client_id')['tbt_start_date'].idxmax()]\n",
    "\n",
    "fact_tbt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tbt info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = ['client_id', 'tbt_facility_id', 'tbt_category', 'tbt_start_date', 'tbt_duration' ,'tbt_expected_stop_date', 'tbt_actual_stop_date', 'tbt_registration_number', 'tbt_site', 'tbt_site_detail', 'tbt_outcome']\n",
    "\n",
    "fact_tbt_df = fact_tbt_df[columns_to_add]\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_tbt_df, on='client_id', how='left')\n",
    "fact_sentinel_event_df.head()\n",
    "\n",
    "filtered_df = fact_sentinel_event_df[fact_sentinel_event_df['client_id'] == 'D2F9D495-4A71-B74B-B8C4-A04FA8369060']\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_tpt dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_tpt_confs = {\n",
    "    \"query\": \"SELECT idpatient, idfacilitycreate, iptRegimen, startDate, duration, stopDateExpected, stopDateActual , CASE  WHEN stopReason = '1' THEN 'Completed TPT' WHEN stopReason = '2' THEN 'Cough' WHEN stopReason = '3' THEN 'Confirmed TB' WHEN stopReason = '4' THEN 'Hepatitis' WHEN stopReason = '5' THEN 'Neuropathy' WHEN stopReason = '6' THEN 'Poor Adherence' WHEN stopReason = '7' THEN 'Medicine Out Of Stock' WHEN stopReason = '8' THEN stopReasonOther ELSE '' END AS stopReason, status, adherenceDetail FROM ipt\",\n",
    "    \"cols\": ['client_id', 'tpt_facility_id', 'tpt_regimen', 'tpt_start_date', 'tpt_duration' ,'tpt_expected_stop_date', 'tpt_actual_stop_date', 'tpt_stop_reason', 'tpt_status', 'tpt_adherance']\n",
    "}\n",
    "\n",
    "fact_tpt_query = fact_tpt_confs.get(\"query\")\n",
    "fact_tpt_cols = fact_tpt_confs.get(\"cols\")\n",
    "\n",
    "fact_tpt_data = fetch_file_maker_data(fact_tpt_query, fm_connection)\n",
    "fact_tpt_df = pd.DataFrame(fact_tpt_data, columns=fact_tpt_cols)\n",
    "\n",
    "fact_tpt_df['tpt_start_date'] = pd.to_datetime(fact_tpt_df['tpt_start_date'], errors='coerce')\n",
    "fact_tpt_df['tpt_expected_stop_date'] = pd.to_datetime(fact_tpt_df['tpt_expected_stop_date'], errors='coerce')\n",
    "fact_tpt_df['tpt_actual_stop_date'] = pd.to_datetime(fact_tpt_df['tpt_actual_stop_date'], errors='coerce')\n",
    "\n",
    "fact_tpt_df['tpt_duration_two'] = (\n",
    "    (fact_tpt_df['tpt_actual_stop_date'].dt.year - fact_tpt_df['tpt_start_date'].dt.year) * 12 +\n",
    "    (fact_tpt_df['tpt_actual_stop_date'].dt.month - fact_tpt_df['tpt_start_date'].dt.month)\n",
    ")\n",
    "\n",
    "fact_tpt_df = fact_tpt_df.dropna(subset=['tpt_start_date'])\n",
    "\n",
    "fact_tpt_df = fact_tpt_df.loc[fact_tpt_df.groupby('client_id')['tpt_start_date'].idxmax()]\n",
    "\n",
    "fact_tpt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute TPT status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tpt_status_two(row):\n",
    "    if pd.notna(row['tpt_actual_stop_date']):\n",
    "        if row['tpt_regimen'] == '3HP' and row['tpt_duration'] >= 70:\n",
    "            return 'Up-to-date on TPT'\n",
    "        elif row['tpt_regimen'] in ['9H','6H'] and row['tpt_duration'] >= 140:\n",
    "            return 'Up-to-date on TPT'\n",
    "        elif row['tpt_regimen'] in ['3H', '6H']:\n",
    "            return 'Up-to-date on TPT'\n",
    "    elif pd.notna(row['tpt_start_date']) and pd.isna(row['tpt_actual_stop_date']):\n",
    "        return 'Have not completed TPT'\n",
    "    return 'Never initiated TPT'\n",
    "\n",
    "fact_tpt_df['tpt_status_two'] = fact_tpt_df.apply(compute_tpt_status_two, axis=1)\n",
    "\n",
    "fact_tpt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tpt info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = ['client_id', 'tpt_facility_id', 'tpt_regimen', 'tpt_start_date', 'tpt_duration', 'tpt_duration_two' ,'tpt_expected_stop_date', 'tpt_actual_stop_date', 'tpt_stop_reason', 'tpt_status', 'tpt_status_two', 'tpt_adherance']\n",
    "\n",
    "fact_tpt_df = fact_tpt_df[columns_to_add]\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_tpt_df, on='client_id', how='left')\n",
    "fact_sentinel_event_df.head()\n",
    "\n",
    "filtered_df = fact_sentinel_event_df[fact_sentinel_event_df['client_id'] == 'D2F9D495-4A71-B74B-B8C4-A04FA8369060']\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_lab dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_lab_confs = {\n",
    "    \"query\": \"SELECT l.idpatient, l.idfacilitycreate, l.orderDate, l.result, l.resultDate, lm.name, l.status FROM lab l INNER JOIN LabMaster lm ON lm.id=l.idtest\",\n",
    "    \"cols\": ['client_id', 'lab_facility_id', 'order_date', 'lab_result', 'result_date', 'test_name','status' ]\n",
    "}\n",
    "\n",
    "fact_lab_query = fact_lab_confs.get(\"query\")\n",
    "fact_lab_cols = fact_lab_confs.get(\"cols\")\n",
    "\n",
    "fact_lab_data = fetch_file_maker_data(fact_lab_query, fm_connection)\n",
    "fact_lab_df = pd.DataFrame(fact_lab_data, columns=fact_lab_cols)\n",
    "\n",
    "fact_lab_df['order_date'] = pd.to_datetime(fact_lab_df['order_date'], errors='coerce')\n",
    "fact_lab_df['result_date'] = pd.to_datetime(fact_lab_df['result_date'], errors='coerce')\n",
    "\n",
    "\n",
    "fact_lab_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_first_viral_load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_last_viral_load_tests_df = fact_lab_df[fact_lab_df['test_name'] == 'Viral Load']\n",
    "fact_first_viral_load_tests_df = fact_last_viral_load_tests_df.sort_values('order_date').groupby('client_id').first().reset_index()\n",
    "\n",
    "fact_first_viral_load_tests_df['lab_result'] = pd.to_numeric(fact_first_viral_load_tests_df['lab_result'], errors='coerce')\n",
    "\n",
    "def categorize_result(result):\n",
    "    if result < 40:\n",
    "        return 'Suppressed'\n",
    "    elif 40 <= result <= 1000:\n",
    "        return 'LLV'\n",
    "    else:\n",
    "        return 'Unsuppressed'\n",
    "\n",
    "fact_first_viral_load_tests_df['category'] = fact_first_viral_load_tests_df['lab_result'].apply(categorize_result)\n",
    "\n",
    "fact_first_viral_load_tests_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_last_viral_load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_last_viral_load_tests_df = fact_last_viral_load_tests_df.sort_values('order_date').groupby('client_id').last().reset_index()\n",
    "fact_last_viral_load_tests_df['lab_result'] = pd.to_numeric(fact_last_viral_load_tests_df['lab_result'], errors='coerce')\n",
    "\n",
    "def categorize_result(result):\n",
    "    if result < 40:\n",
    "        return 'Suppressed'\n",
    "    elif 40 <= result <= 1000:\n",
    "        return 'LLV'\n",
    "    else:\n",
    "        return 'Unsuppressed'\n",
    "\n",
    "fact_last_viral_load_tests_df['category'] = fact_last_viral_load_tests_df['lab_result'].apply(categorize_result)\n",
    "\n",
    "fact_last_viral_load_tests_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add first viral load info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = {\n",
    "    'order_date': 'first_viral_load_order_date',\n",
    "    'result_date': 'first_viral_load_result_date', \n",
    "    'lab_result': 'first_viral_load_result',\n",
    "    'lab_facility_id': 'first_viral_load_facility_id',\n",
    "    'category': 'first_viral_load_result_category',\n",
    "    'status': 'first_viral_load_result_status',\n",
    "}\n",
    "\n",
    "fact_first_viral_load_tests_df = fact_first_viral_load_tests_df[list(columns_to_add.keys()) + ['client_id']].rename(columns=columns_to_add)\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_first_viral_load_tests_df, on='client_id', how='left')\n",
    "\n",
    "fact_sentinel_event_df.head()\n",
    "\n",
    "filtered_df = fact_sentinel_event_df[fact_sentinel_event_df['client_id'] == 'D2F9D495-4A71-B74B-B8C4-A04FA8369060']\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add last viral load info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = {\n",
    "    'order_date': 'last_viral_load_order_date',\n",
    "    'result_date': 'last_viral_load_result_date', \n",
    "    'lab_result': 'last_viral_load_result',\n",
    "    'lab_facility_id': 'last_viral_load_facility_id',\n",
    "    'category': 'last_viral_load_result_category',\n",
    "    'status': 'last_viral_load_result_status',\n",
    "}\n",
    "\n",
    "fact_last_visit_df = fact_last_viral_load_tests_df[list(columns_to_add.keys()) + ['client_id']].rename(columns=columns_to_add)\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_last_visit_df, on='client_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add duration of ART in months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_in_months(date1, date2):\n",
    "    if pd.isnull(date1) or pd.isnull(date2):\n",
    "        return None\n",
    "    return (date1.year - date2.year) * 12 + date1.month - date2.month\n",
    "\n",
    "fact_sentinel_event_df['months_since_art_start'] = fact_sentinel_event_df.apply(lambda row: diff_in_months(max_last_visit_date, row['art_start_date']), axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add program status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_status(row):\n",
    "    if pd.isna(row['death_date']) and row['patient_status'] != 'Transferred Out':\n",
    "        if row['last_next_visit_date'] > max_last_visit_date:\n",
    "            return 'Active on ART'\n",
    "        elif (max_last_visit_date - row['last_next_visit_date']).days <= 28:\n",
    "            return 'Active on ART: Missed Appointment'\n",
    "        elif  29 < (max_last_visit_date - row['last_next_visit_date']).days <= 90:\n",
    "            return 'IIT: Missed Appointment'\n",
    "        elif pd.isnull(row['art_start_date']) and row['patient_status'] == 'Opt Out':\n",
    "            return 'Never initiated on ART'\n",
    "        elif (max_last_visit_date - row['last_next_visit_date']).days > 90:\n",
    "            return 'Lost'\n",
    "    elif pd.isna(row['death_date']):\n",
    "        return 'Deceased'\n",
    "    elif row['patient_status'] != 'Transferred Out':\n",
    "        return 'Transferred Out'\n",
    "    \n",
    "fact_sentinel_event_df['client_status'] = fact_sentinel_event_df.apply(classify_status, axis=1)\n",
    "\n",
    "fact_sentinel_event_df['tx_curr'] = fact_sentinel_event_df['client_status'].apply(\n",
    "    lambda status: 'Yes' if status in ['Active on ART', 'Active on ART: Missed Appointment'] else 'No'\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add patient ages at different stages cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df['hiv_confirmation_age'] = (fact_sentinel_event_df['hiv_confirmation_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['hiv_enrollment_age'] = (fact_sentinel_event_df['hiv_enrollment_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['first_viral_load_result_age'] = (fact_sentinel_event_df['first_viral_load_result_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['last_viral_load_result_age'] = (fact_sentinel_event_df['last_viral_load_result_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['first_visit_age'] = (fact_sentinel_event_df['first_visit_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['last_visit_age'] = (fact_sentinel_event_df['last_visit_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['current_age'] = (pd.to_datetime('today') - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add ART Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df['art_duration'] = (\n",
    "    (max_last_visit_date.year - fact_sentinel_event_df['art_start_date'].dt.year) * 12 +\n",
    "    (max_last_visit_date.month - fact_sentinel_event_df['art_start_date'].dt.month)\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df['art_duration'] = (max_last_visit_date - fact_sentinel_event_df['art_start_date']).dt.days // 365.25\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Days since last visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df['days_since_last_visit'] = (max_last_visit_date - fact_sentinel_event_df['last_visit_date']).dt.days\n",
    "fact_sentinel_event_df['years_since_last_visit'] = (max_last_visit_date - fact_sentinel_event_df['last_visit_date']).dt.days // 365.25\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dim age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59, 64, float('inf')]\n",
    "labels = ['0-4', '5-9', '10-14','15-19','20-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-64', '65+']\n",
    "\n",
    "dim_age_group_df = pd.DataFrame({\n",
    "    'current_age': range(1, 101)\n",
    "})\n",
    "\n",
    "dim_age_group_df['pepfar_age_group'] = pd.cut(dim_age_group_df['current_age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "dim_age_group_df['paeds_adult_age_group'] = dim_age_group_df['current_age'].apply(lambda x: '0-18 yr old (Pediatric)' if x <= 18 else '19+ yr old (Adult)')\n",
    "\n",
    "def tri_pillar_classify(age):\n",
    "    if 0 <= age <= 18:\n",
    "        return '0-18'\n",
    "    elif age == 19:\n",
    "        return '19'\n",
    "    elif 20 <= age <= 39:\n",
    "        return '20-39'\n",
    "    else:\n",
    "        return '39+'\n",
    "    \n",
    "dim_age_group_df['tri_pillar_age_group'] = dim_age_group_df['current_age'].apply(tri_pillar_classify)\n",
    "\n",
    "dim_age_group_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add age group sort column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_pillar_age_group_val(age):\n",
    "    if 0 <= age <= 18:\n",
    "        return 1\n",
    "    elif age == 19:\n",
    "        return 2\n",
    "    elif 20 <= age <= 39:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "dim_age_group_df['tri_pillar_age_group_val'] = dim_age_group_df['current_age'].apply(tri_pillar_age_group_val)\n",
    "\n",
    "dim_age_group_df['paeds_adult_age_group_val'] = dim_age_group_df['paeds_adult_age_group'].apply(\n",
    "    lambda x: 1 if x == '0-18 yr old (Pediatric)' else 2\n",
    ")\n",
    "\n",
    "def pepfar_age_group_val(label):\n",
    "    if label == '0-4':\n",
    "        return 1\n",
    "    elif label == '5-9':\n",
    "        return 2\n",
    "    elif label == '10-14':\n",
    "        return 3\n",
    "    elif label == '15-19':\n",
    "        return 4\n",
    "    elif label == '20-24':\n",
    "        return 5\n",
    "    elif label == '25-29':\n",
    "        return 6\n",
    "    elif label == '30-34':\n",
    "        return 7\n",
    "    elif label == '35-39':\n",
    "        return 8\n",
    "    elif label == '40-44':\n",
    "        return 9\n",
    "    elif label == '45-49':\n",
    "        return 10\n",
    "    elif label == '50-54':\n",
    "        return 11\n",
    "    elif label == '55-59':\n",
    "        return 12\n",
    "    elif label == '60-64':\n",
    "        return 13\n",
    "    else:  # '65+'\n",
    "        return 14\n",
    "\n",
    "dim_age_group_df['pepfar_age_group_val'] = dim_age_group_df['pepfar_age_group'].apply(pepfar_age_group_val)\n",
    "\n",
    "dim_age_group_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a column that contains current age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df = fact_sentinel_event_df.merge(\n",
    "    dim_age_group_df[['current_age', 'pepfar_age_group', 'pepfar_age_group_val','paeds_adult_age_group', 'paeds_adult_age_group_val','tri_pillar_age_group','tri_pillar_age_group_val']], \n",
    "    on='current_age',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the difference in months between max_last_visit_date and last_viral_load_result_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_months_since_last_viral_load(date):\n",
    "    return (max_last_visit_date.year - date.year) * 12 + max_last_visit_date.month - date.month\n",
    "\n",
    "fact_sentinel_event_df['months_since_last_viral_load'] = fact_sentinel_event_df['last_viral_load_result_date'].apply(calculate_months_since_last_viral_load)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add VL Eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_vl_eligibility(row):\n",
    "    if row['last_viral_load_result'] >= 40 and 3 < row['months_since_last_viral_load'] <= 6:\n",
    "        return 'Recent (Slightly delayed)'\n",
    "    elif (row['last_breast_feeding'] == 'yes' or row['last_pregnancy_status'] == 'yes') and 3 < row['months_since_last_viral_load'] <= 6:\n",
    "        return 'Recent (Slightly delayed)'\n",
    "    elif row['current_age'] > 18 and not (row['last_breast_feeding'] == 'yes' or row['last_pregnancy_status'] == 'yes') and row['last_viral_load_result'] < 40 and 12 < row['months_since_last_viral_load'] <= 18:\n",
    "        return 'Recent (Slightly delayed)'\n",
    "    elif row['current_age'] <= 18 and not (row['last_breast_feeding'] == 'yes' or row['last_pregnancy_status'] == 'yes') and row['last_viral_load_result'] < 40 and 6 < row['months_since_last_viral_load'] <= 12:\n",
    "        return 'Recent (Slightly delayed)'\n",
    "    \n",
    "    elif row['art_start_date'] <= max_last_visit_date - pd.DateOffset(days=180):\n",
    "        if row['last_viral_load_result'] >= 40 and row['months_since_last_viral_load'] <= 3:\n",
    "            return 'Monitored per Guidelines'\n",
    "        elif (row['last_breast_feeding'] == 'yes' or row['last_pregnancy_status'] == 'yes') and row['months_since_last_viral_load'] <= 3:\n",
    "            return 'Monitored per Guidelines'\n",
    "        elif row['current_age'] <= 18 and not (row['last_breast_feeding'] == 'yes' or row['last_pregnancy_status'] == 'yes') and row['last_viral_load_result'] < 40 and row['months_since_last_viral_load'] <= 6:\n",
    "            return 'Monitored per Guidelines'\n",
    "        elif row['current_age'] > 18 and not (row['last_breast_feeding'] == 'yes' or row['last_pregnancy_status'] == 'yes') and row['last_viral_load_result'] < 40 and row['months_since_last_viral_load'] <= 12:\n",
    "            return 'Monitored per Guidelines'\n",
    "    \n",
    "    elif row['last_viral_load_result'] >= 40 and row['months_since_last_viral_load'] > 6:\n",
    "        return 'Delayed'\n",
    "    elif (row['last_breast_feeding'] == 'yes' or row['last_pregnancy_status'] == 'yes') and row['months_since_last_viral_load'] > 6:\n",
    "        return 'Delayed'\n",
    "    elif row['current_age'] > 18 and not (row['last_breast_feeding'] == 'yes' or row['last_pregnancy_status'] == 'yes') and row['last_viral_load_result'] < 40 and row['months_since_last_viral_load'] > 18:\n",
    "        return 'Delayed'\n",
    "    elif row['current_age'] <= 18 and not (row['last_breast_feeding'] == 'yes' or row['last_pregnancy_status'] == 'yes') and row['last_viral_load_result'] < 40 and row['months_since_last_viral_load'] > 12:\n",
    "        return 'Delayed'\n",
    "    \n",
    "    return 'Unclassified'  \n",
    "\n",
    "fact_sentinel_event_df['vl_eligibility'] = fact_sentinel_event_df.apply(classify_vl_eligibility, axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add reason for next VL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_vl_reason(row):\n",
    "    if row['months_since_art_start'] is not None and row['months_since_art_start'] > 6 and pd.notnull(row['art_start_date']) and pd.isnull(row['first_viral_load_result_date']):\n",
    "        return 'First Test'\n",
    "    elif row['months_since_last_viral_load'] > 3 and row['last_pregnancy_status'] == 'Yes':\n",
    "        return 'Pregnant Women'\n",
    "    elif row['months_since_last_viral_load'] > 3 and row['last_breast_feeding'] == 'Yes':\n",
    "        return 'BF Women'\n",
    "    elif row['months_since_last_viral_load'] > 3 and row['last_viral_load_result_category'] == 'LLV':\n",
    "        return 'Low Level Viraemia'\n",
    "    elif row['months_since_last_viral_load'] > 6 and row['last_visit_age'] <= 19:\n",
    "        return 'Children And Adolescents Under 19'\n",
    "    elif row['months_since_last_viral_load'] > 12 and row['last_visit_age'] > 19:\n",
    "        return 'Treatment Monitoring For Adults'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "fact_sentinel_event_df['reason_for_next_vl'] = fact_sentinel_event_df.apply(categorize_vl_reason, axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add next VL date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_next_vl_date(row):\n",
    "    if pd.isnull(row['last_viral_load_result_date']):\n",
    "        return None\n",
    "    elif row['reason_for_next_vl'] == 'First Test':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=6)\n",
    "    elif row['reason_for_next_vl'] == 'Pregnant Women':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=3)\n",
    "    elif row['reason_for_next_vl'] == 'BF Women':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=3)\n",
    "    elif row['reason_for_next_vl'] == 'Low Level Viraemia':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=6)\n",
    "    elif row['reason_for_next_vl'] == 'Children And Adolescents Under 19':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=6)\n",
    "    elif row['reason_for_next_vl'] == 'Treatment Monitoring For Adults':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=12)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "fact_sentinel_event_df['next_vl_date'] = fact_sentinel_event_df.apply(calculate_next_vl_date, axis=1)\n",
    "\n",
    "print(fact_sentinel_event_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute if patient has ever been initiated on ART  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_has_been_initiated_on_art(row):\n",
    "    return 'Yes' if pd.notna(row['art_start_date']) else 'No'\n",
    "    \n",
    "fact_sentinel_event_df['has_ever_been_initiated_on_art'] = fact_sentinel_event_df.apply(lambda row: determine_has_been_initiated_on_art(row), axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if last VL is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_last_viral_load_valid(row, df):\n",
    "    df_row = df.iloc[row.name]\n",
    "    if df_row['months_since_last_viral_load'] <= 12:\n",
    "        return 'Yes'\n",
    "    elif pd.notna(df_row['art_start_date']):\n",
    "        return 'No'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "fact_sentinel_event_df['is_last_viral_load_valid'] = fact_sentinel_event_df.apply(lambda row: is_last_viral_load_valid(row, fact_sentinel_event_df), axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if patient is virally suppressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_is_virally_suppressed(row, df):\n",
    "    row = df.iloc[row.name]\n",
    "    if row['is_last_viral_load_valid'] == 'Yes' and row['last_viral_load_result_category'] == 'Suppressed' and row['last_next_visit_date'] >= max_last_visit_date:\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "fact_sentinel_event_df['is_virally_suppressed'] = fact_sentinel_event_df.apply(determine_is_virally_suppressed, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if patient is not virally suppressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_is_not_virally_suppressed(row, df):\n",
    "    row = df.iloc[row.name]\n",
    "    if row['is_last_viral_load_valid'] == 'Yes' and row['last_viral_load_result_category'] == 'Unsuppressed' and row['last_next_visit_date'] >= max_last_visit_date:\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "fact_sentinel_event_df['is_not_virally_suppressed'] = fact_sentinel_event_df.apply(determine_is_not_virally_suppressed, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute needs VL test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_needs_VL_test(row, df):\n",
    "    row = df.iloc[row.name]\n",
    "    if (row['months_since_art_start'] > 6 and pd.notna(row['first_viral_load_result_date']) and row['last_breast_feeding'] != 'Yes') and (row['is_not_virally_suppressed'] != 1 and row['is_virally_suppressed'] != 1):\n",
    "        return 'Yes'\n",
    "    elif (row['last_viral_load_result_category'] == 'Suppressed' and row['last_next_visit_date'] >= max_last_visit_date and row['months_since_last_viral_load'] > 12 and row['last_breast_feeding'] != 'Yes') and (row['is_not_virally_suppressed'] != 1 and row['is_virally_suppressed'] != 1):\n",
    "        return 'Yes'\n",
    "    elif (row['last_viral_load_result_category'] == 'Unsuppressed' and row['last_next_visit_date'] >= max_last_visit_date and row['months_since_last_viral_load'] > 3 and row['last_breast_feeding'] != 'Yes') and (row['is_not_virally_suppressed'] != 1 and row['is_virally_suppressed'] != 1):\n",
    "        return 'Yes'\n",
    "    elif (row['months_since_art_start'] > 3 and pd.notna(row['first_viral_load_result_date']) and row['last_breast_feeding'] == 'Yes') and (row['is_not_virally_suppressed'] != 1 and row['is_virally_suppressed'] != 1):\n",
    "        return 'Yes'\n",
    "    elif (row['last_viral_load_result_category'] == 'Suppressed' and row['last_next_visit_date'] >= max_last_visit_date and row['months_since_last_viral_load'] > 6 and row['last_breast_feeding'] == 'Yes') and (row['is_not_virally_suppressed'] != 1 and row['is_virally_suppressed'] != 1):\n",
    "        return 'Yes'\n",
    "    elif (row['last_viral_load_result_category'] == 'Unsuppressed' and row['last_next_visit_date'] >= max_last_visit_date and row['months_since_last_viral_load'] > 3 and row['last_breast_feeding'] == 'Yes') and (row['is_not_virally_suppressed'] != 1 and row['is_virally_suppressed'] != 1):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "fact_sentinel_event_df['needs_vl_test'] = fact_sentinel_event_df.apply(determine_needs_VL_test, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Six MMP Eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_six_mmp_eligibility(row, df):\n",
    "    row = df.iloc[row.name]\n",
    "    if (row['current_age'] > 2 and (pd.isnull(row['tbt_start_date']) or row['tbt_duration'] >= 6) and (row['is_last_viral_load_valid'] == 'Yes' and row['last_viral_load_result'] < 40) and row['months_since_art_start'] >= 6  and (row['last_regimen_line'] == '1' or row['last_regimen_line'] == '2') and pd.isnull(row['last_oi_other'])):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "bins = [0, 3, 6, float('inf')]\n",
    "labels = ['< 3 MMP', '3-5 MMP', '6+ MMP']\n",
    "\n",
    "fact_sentinel_event_df['mmp_status'] = pd.cut(fact_sentinel_event_df['last_visit_duration'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "max_last_visit_month = max_last_visit_date.month\n",
    "max_last_visit_year = max_last_visit_date.year\n",
    "\n",
    "fact_sentinel_event_df['last_visit_month'] = fact_sentinel_event_df['last_visit_date'].dt.month\n",
    "fact_sentinel_event_df['last_visit_year'] = fact_sentinel_event_df['last_visit_date'].dt.year\n",
    "\n",
    "fact_sentinel_event_df['mmp_status_current'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: row['mmp_status'] if (row['last_visit_month'] == max_last_visit_month and row['last_visit_year'] == max_last_visit_year) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df['mmp_status_adult'] = fact_sentinel_event_df['paeds_adult_age_group'].apply(lambda x: 'Yes' if 'adult' in str(x).lower() else None)\n",
    "\n",
    "fact_sentinel_event_df['mmp_status_paed'] = fact_sentinel_event_df['paeds_adult_age_group'].apply(lambda x: 'Yes' if 'pediatric' in str(x).lower() else None)\n",
    "\n",
    "fact_sentinel_event_df['six_mmp_eligible'] = fact_sentinel_event_df.apply(determine_six_mmp_eligibility, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Six MMP Eligibility But Not Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df['six_mmp_eligible_but_not_given'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: 'Yes' if row['six_mmp_eligible'] == 'Yes' and row['mmp_status'] != '6+ MMP' else 'No', \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute currrent cascade status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_art_outcomes(row):\n",
    "    if row['is_virally_suppressed'] == 'Yes':\n",
    "        return 'VL Suppressed'\n",
    "    elif row['is_not_virally_suppressed'] == 'Yes':\n",
    "        return 'VL Not Suppressed'\n",
    "    elif row['needs_vl_test'] == 'Yes':\n",
    "        return 'Needs VL Test'\n",
    "    elif row['months_since_art_start'] < 6:\n",
    "        return 'Recently initiated'\n",
    "    elif row['has_ever_been_initiated_on_art'] == 'No':\n",
    "        return 'Not initiated on ART'\n",
    "    elif row['years_since_last_visit'] > 2:\n",
    "        return 'Case Closed'\n",
    "    elif row['patient_status'] == 'Deceased':\n",
    "        return 'Died'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "fact_sentinel_event_df['art_outcomes'] = fact_sentinel_event_df.apply(determine_art_outcomes, axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change dates from datetime to date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df = fact_sentinel_event_df.apply(lambda col: col.dt.date if col.dtype == 'datetime64[ns]' else col)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(col):\n",
    "    if '_id' in col:\n",
    "        return '__' + col\n",
    "    else:\n",
    "        col = col.replace('_', ' ').title()\n",
    "        col = col.replace('Tpt', 'TPT')\n",
    "        col = col.replace('Tbt', 'TBT')\n",
    "        col = col.replace('Hiv', 'HIV')\n",
    "        col = col.replace('Art', 'ART')\n",
    "        col = col.replace('Iit', 'IIT')\n",
    "        col = col.replace('Mmp', 'MMP')\n",
    "        col = col.replace('Pmtct', 'PMTCT')\n",
    "        col = col.replace('Vl', 'Viral Load')\n",
    "        col = col.replace('Tx Curr', 'TX Curr')\n",
    "        col = col.replace('Oi', 'OI')\n",
    "        col = col.replace('Lmp', 'LMP')\n",
    "        col = col.replace('Edd', 'EDD')\n",
    "        col = col.replace('Who', 'WHO')\n",
    "        col = col.replace('Tb', 'TB')\n",
    "        return col\n",
    "\n",
    "fact_sentinel_event_df.columns = [rename_columns(col) for col in fact_sentinel_event_df.columns]\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Destination Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = destination_environment.get(\"server\")\n",
    "database = destination_environment.get(\"database\")\n",
    "port = destination_environment.get(\"port\")\n",
    "username = destination_environment.get(\"username\")\n",
    "password = destination_environment.get(\"password\")\n",
    "\n",
    "connection_url = ('postgresql://{0}:{1}@{2}:{3}/{4}'\n",
    "                          .format(username, password, server, port, database))\n",
    "\n",
    "engine = create_engine(connection_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write dim age group to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'dim_age_group'\n",
    "\n",
    "dim_age_group_df.to_sql(table_name, con=engine, if_exists='replace', index=False, schema='analysis')\n",
    "\n",
    "dim_age_group_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write sentinel event to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'fact_sentinel_event'\n",
    "\n",
    "fact_sentinel_event_df.to_sql(table_name, con=engine, if_exists='replace', index=False, schema='analysis')\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dim_pat_df\n",
    "del fact_hiv_diagnosis_df\n",
    "del fact_hiv_enrolment_df\n",
    "del fact_first_visit_df\n",
    "del fact_last_visit_df\n",
    "del fact_visits_df\n",
    "del fact_lab_df\n",
    "del fact_tpt_df\n",
    "del fact_meas_df\n",
    "del fact_first_viral_load_tests_df\n",
    "del fact_last_viral_load_tests_df\n",
    "del fact_tbt_df\n",
    "del fact_tsfr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
